#!/usr/bin/env python3
"""
Simple test for the ResearcherAgent without requiring LLM
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../..'))

from backend.agents.researcher import ResearcherAgent

def test_researcher_agent():
    print("ğŸ” Testing ResearcherAgent Configuration...")
    
    # Test agent creation
    try:
        researcher_agent = ResearcherAgent()
        print("âœ… ResearcherAgent initialized successfully")
        
        # Test tools
        print(f"ğŸ“ Directory tool: {researcher_agent.directory_tool.name}")
        print(f"ğŸ“„ File tool: {researcher_agent.file_read_tool.name}")
        
        # Test agent creation
        agent = researcher_agent.create_agent()
        print(f"âœ… Agent created: {agent.role}")
        print(f"ğŸ¯ Goal: {agent.goal}")
        print(f"ğŸ› ï¸ Tools: {[tool.name for tool in agent.tools]}")
        
        # Test task configuration
        tasks = researcher_agent.get_tasks()
        print(f"ğŸ“‹ Tasks configured: {len(tasks)}")
        for i, task in enumerate(tasks):
            print(f"   Task {i+1}: {task['description'][:100]}...")
        
        print("\nğŸ‰ ResearcherAgent is properly configured!")
        return True
        
    except Exception as e:
        print(f"âŒ ResearcherAgent test failed: {e}")
        return False

if __name__ == "__main__":
    success = test_researcher_agent()
    if success:
        print("\nâœ… ResearcherAgent is ready to use!")
        print("ğŸ’¡ To test with actual LLM, you need to:")
        print("   1. Set up OpenAI API key: export OPENAI_API_KEY=your_key")
        print("   2. Or configure another LLM provider in the agent")
        print("   3. Run a full crew with tasks")
    else:
        print("\nâŒ ResearcherAgent needs fixes!")